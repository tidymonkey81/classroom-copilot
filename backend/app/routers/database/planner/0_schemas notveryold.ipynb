{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming variables in a way that indicates their data type and purpose can significantly improve the readability and maintainability of your code. Here are some suggestions for naming conventions that include both the type of data and its purpose:\n",
    "\n",
    "1. **For Lists:** Use a plural form and include the type of elements the list contains. For example:\n",
    "   - `topicNodeList` or `topicNodes` instead of `topic_excel_node_list` (indicating it's a list of `TopicNode` objects).\n",
    "   - `topicHelperDataList` or `topicHelpers` instead of `topic_excel_helper_list` (indicating it's a list of helper data dictionaries).\n",
    "\n",
    "2. **For Dictionaries:** Include `Dict` in the name, along with an indication of what the dictionary holds. For example:\n",
    "   - `topicNodeDataDict` instead of `topic_node_data` (indicating it's a dictionary of data for a `TopicNode`).\n",
    "   - `topicHelperDataDict` instead of `topic_excel_helper_data` (indicating it's a dictionary of helper data).\n",
    "\n",
    "3. **For Processed Data:** Use a name that indicates both the original type and that it's been processed. For example:\n",
    "   - `processedTopicNodeDataDict` instead of `topic_excel_node_data_processed` (indicating it's a processed dictionary of `TopicNode` data).\n",
    "\n",
    "4. **For Combined Data:** Use a name that indicates it's a combined structure, along with what it contains. For example:\n",
    "   - `topicNodeAndHelperDict` instead of `combined_data` (indicating it's a dictionary containing both a `TopicNode` and its helper data).\n",
    "\n",
    "5. **For Default Values:** Specify what the defaults are for. For example:\n",
    "   - `defaultTopicValuesDict` instead of `default_values` (indicating it's a dictionary of default values for topics).\n",
    "\n",
    "Here's how your code might look with these naming conventions:\n",
    "\n",
    "```python\n",
    "topicNodeList = []\n",
    "topicHelperDataList = []\n",
    "defaultTopicValuesDict = {\n",
    "    'topic_assessment_type': 'Null'\n",
    "}\n",
    "\n",
    "for index, row in topic_df.iterrows():\n",
    "    topicNodeDataDict = {\n",
    "        # your existing code to populate topicNodeDataDict\n",
    "    }\n",
    "    logging.pedantic(f\"Processing row {index}: {topicNodeDataDict}\")\n",
    "\n",
    "    topicHelperDataDict = {\n",
    "        # your existing code to populate topicHelperDataDict\n",
    "    }\n",
    "\n",
    "    processedTopicNodeDataDict = replace_nan_with_default(topicNodeDataDict, defaultTopicValuesDict)\n",
    "\n",
    "    try:\n",
    "        topicNode = TopicNode(**processedTopicNodeDataDict)\n",
    "        topicNodeAndHelperDict = {\n",
    "            'node': topicNode,\n",
    "            'helper': topicHelperDataDict\n",
    "        }\n",
    "        topicNodeList.append(topicNodeAndHelperDict)\n",
    "        logging.pedantic(f\"Appended topicNodeAndHelperDict for row {index}: {topicNodeList}\")\n",
    "    except ValidationError as e:\n",
    "        logging.error(f\"Validation error for row {index}: {e}\")\n",
    "```\n",
    "\n",
    "These names make it clearer what each variable is and what type of data it contains, which can be especially helpful in larger projects or when collaborating with other developers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example usage\n",
    "#topic_schema_instance = schemas.TopicSchema(**topic_data)\n",
    "#topic_node_instance = schema_tools.convert_pydantic_to_neontology(topic_schema_instance, schemas.TopicNode)\n",
    "\n",
    "#topic_lesson_schema_instance = schemas.TopicLessonSchema(**topic_lesson_data)\n",
    "#topic_lesson_node_instance = schema_tools.convert_pydantic_to_neontology(topic_lesson_schema_instance, schemas.TopicLessonNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from schemas import TopicNode, TopicLessonNode, LearningStatementNode\n",
    "from schemas import SchoolOffersSubject, SubjectForKeyStage, KeyStageIncludesTopic, SubjectIncludesTopic, TopicIncludesTopicLesson, TopicIncludesLearningStatement, LearningStatementPartOfTopicLesson\n",
    "import schema_tools as schema_tools\n",
    "import planner as planner\n",
    "import neontology_tools as neon\n",
    "import neo4j_driver_tools as neo4j\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import ValidationError, BaseModel\n",
    "from neontology import BaseNode, BaseRelationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver = neo4j.get_neo4j_driver()\n",
    "neon.init_neo4j_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = planner.get_excel_sheets('planner.xlsx ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = planner['topiclookup_df']\n",
    "lesson_df = planner['lessonlookup_df']\n",
    "statement_df = planner['statementlookup_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_default(data, default_values):\n",
    "    for key in default_values:\n",
    "        if pd.isna(data.get(key, None)):\n",
    "            logging.warning(f\"Replacing NaN in {key} with default value '{default_values[key]}'\")\n",
    "            data[key] = default_values[key]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_excel_node_list = []\n",
    "topic_excel_helper_list = []\n",
    "default_values = {\n",
    "    'topic_assessment_type': 'Null'\n",
    "    }\n",
    "\n",
    "for index, row in topic_df.iterrows():\n",
    "    # Filter and map the row to TopicNode fields\n",
    "    topic_node_data = {\n",
    "        'topic_id': row.get('TopicID'),\n",
    "        'topic_title': row.get('TopicTitle'),\n",
    "        'total_number_of_lessons_for_topic': row.get('TotalNumberOfLessonsForTopic'),\n",
    "        'topic_type': row.get('TopicType'),\n",
    "        'topic_assessment_type': row.get('TopicAssessmentType')\n",
    "    }\n",
    "    logging.pedantic(f\"Processing row {index}: {topic_node_data}\")\n",
    "    topic_excel_helper_data = {\n",
    "        'topic_source': row.get('TopicSource'),\n",
    "        'topic_department': row.get('TopicDepartment'),\n",
    "        'topic_key_stage': row.get('TopicKeyStage'),\n",
    "        'topic_year': row.get('TopicYear'),\n",
    "        'topic_subject': row.get('TopicSubject'),\n",
    "        'topic_sequence': row.get('TopicSequence')\n",
    "    }\n",
    "    # Replace NaN values with defaults\n",
    "    topic_excel_node_data_processed = replace_nan_with_default(topic_node_data, default_values)\n",
    "    logging.pedantic(f\"Processed row {index}: {topic_excel_node_data_processed}\")\n",
    "\n",
    "    # Create a TopicNode instance for each row\n",
    "    try:\n",
    "        topic_node = TopicNode(**topic_excel_node_data_processed)\n",
    "        logging.pedantic(f\"TopicNode instance created for row {index}: {topic_node}\")\n",
    "        combined_data = {\n",
    "            'node': topic_node,\n",
    "            'helper': topic_excel_helper_data\n",
    "        }\n",
    "        logging.pedantic(f\"Combined data for row {index}: {combined_data}\")\n",
    "        topic_excel_node_list.append(combined_data)\n",
    "        logging.pedantic(f\"Appended new combined data to topic_excel_node_list, current length: {len(topic_excel_node_list)}\")\n",
    "    except ValidationError as e:\n",
    "        logging.error(f\"Validation error for row {index}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, use the create_or_merge_neontology_node function to add these nodes to your Neo4j database\n",
    "for node_data in topic_excel_node_list:\n",
    "    try:\n",
    "        logging.pedantic(f\"Processing node: {node_data}\")\n",
    "        neon.create_or_merge_neontology_node(node_data['node'], operation='merge')\n",
    "        logging.pedantic(f\"Node processed: {node_data}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing node: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_lesson_excel_node_list = []\n",
    "topic_lesson_excel_helper_list = []\n",
    "default_values = {\n",
    "    'topic_lesson_title': 'Null',  # Corrected default value key\n",
    "    'topic_lesson_type': 'Null',  # Corrected default value key\n",
    "    'topic_lesson_length': 1,             # Corrected default value key\n",
    "    'topic_lesson_suggested_activities': 'Null',  # Corrected default value key\n",
    "    'topic_lesson_skills_learned': 'Null',  # Corrected default value key\n",
    "    'topic_lesson_weblinks': 'Null',   # Corrected default value key\n",
    "}\n",
    "\n",
    "for index, row in lesson_df.iterrows():\n",
    "    # Filter and map the row to TopicLessonNode fields\n",
    "    topic_lesson_node_data = {\n",
    "        'topic_lesson_id': row.get('LessonID'),\n",
    "        'topic_lesson_title': row.get('LessonTitle', default_values['topic_lesson_title']),\n",
    "        'topic_lesson_type': row.get('TopicLessonType', default_values['topic_lesson_type']),\n",
    "        'topic_lesson_length': row.get('SuggestedNumberOfPeriodsForLesson', default_values['topic_lesson_length']),\n",
    "        'topic_lesson_suggested_activities': row.get('SuggestedActivities', default_values['topic_lesson_suggested_activities']),\n",
    "        'topic_lesson_skills_learned': row.get('SkillsLearned', default_values['topic_lesson_skills_learned']),\n",
    "        'topic_lesson_weblinks': row.get('TopicLessonWeblinks', default_values['topic_lesson_weblinks'])\n",
    "        }\n",
    "    logging.pedantic(f\"topic_lesson_node_data: {topic_lesson_node_data}\")\n",
    "    topic_lesson_excel_helper_data = {\n",
    "        'topic_lesson_source': row.get('TopicSource'),\n",
    "        'topic_lesson_department': row.get('TopicDepartment'),\n",
    "        'topic_lesson_key_stage': row.get('TopicKeyStage'),\n",
    "        'topic_lesson_topic_id': row.get('TopicID'),\n",
    "        'topic_lesson_topic_year': row.get('TopicYear'),\n",
    "        'topic_lesson_topic_subject': row.get('TopicSubject'),\n",
    "        'topic_lesson_topic_sequence': row.get('TopicSequence'),\n",
    "        'topic_lesson_lesson_sequence': row.get('LessonSequence'),\n",
    "        'topic_lesson_learning_objective': row.get('LessonLearningObjective'),\n",
    "        }\n",
    "    logging.pedantic(f\"topic_lesson_excel_helper_list: {topic_lesson_excel_helper_list}\")\n",
    "\n",
    "    # Replace NaN values with defaults\n",
    "    topic_lesson_excel_node_data_processed = replace_nan_with_default(topic_lesson_node_data, default_values)\n",
    "    logging.pedantic(f\"topic_lesson_excel_node_list_processed_data: {topic_lesson_excel_node_data_processed}\")\n",
    "\n",
    "    # Create a TopicLessonNode instance for each row\n",
    "    try:\n",
    "        topic_lesson_node = TopicLessonNode(**topic_lesson_excel_node_data_processed)\n",
    "        logging.pedantic(f\"topic_lesson_node: {topic_lesson_node}\")\n",
    "        combined_data = {\n",
    "            'node': topic_lesson_node,\n",
    "            'helper': topic_lesson_excel_helper_data\n",
    "        }\n",
    "        logging.pedantic(f\"combined_data: {combined_data}\")\n",
    "        topic_lesson_excel_node_list.append(combined_data)\n",
    "        logging.pedantic(f\"Appended new combined data to topic_lesson_excel_node_list, current length: {len(topic_lesson_excel_node_list)}\")\n",
    "    except ValidationError as e:\n",
    "        logging.error(f\"Validation error for row {index}: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, use the create_or_merge_neontology_node function to add these nodes to your Neo4j database\n",
    "for node_data in topic_lesson_excel_node_list:\n",
    "    try:\n",
    "        neon.create_or_merge_neontology_node(node_data['node'], operation='merge')\n",
    "        logging.pedantic(f\"TopicLessonNode instance created for row {index}: {topic_lesson_node}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing node: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_statement_excel_node_list = []\n",
    "learning_statement_excel_helper_list = []\n",
    "default_values = {\n",
    "    # Add default values for fields that might contain NaN\n",
    "    'lesson_learning_statement': 'Null',\n",
    "    'lesson_learning_statement_type': 'Student learning outcome'\n",
    "}\n",
    "\n",
    "for index, row in statement_df.iterrows():\n",
    "    # Filter and map the row to LearningStatementNode fields\n",
    "    learning_statement_node_data = {\n",
    "        'lesson_learning_statement_id': row.get('LearningOutcomeID'),\n",
    "        'lesson_learning_statement': row.get('LearningOutcomeStatement', default_values['lesson_learning_statement']),\n",
    "        'lesson_learning_statement_type': row.get('LearningStatementType', default_values['lesson_learning_statement_type']),\n",
    "    }\n",
    "    logging.pedantic(f\"learning_statement_node_data: {learning_statement_node_data}\")\n",
    "    learning_statement_excel_helper_data = {\n",
    "        'lesson_learning_statement_source': row.get('TopicSource'),\n",
    "        'lesson_learning_statement_department': row.get('TopicDepartment'),\n",
    "        'lesson_learning_statement_key_stage': row.get('TopicKeyStage'),\n",
    "        'lesson_learning_statement_topic_id': row.get('TopicID'),\n",
    "        'lesson_learning_statement_lesson_id': row.get('LessonID'),\n",
    "        'lesson_learning_statement_topic_year': row.get('TopicYear'),\n",
    "        'lesson_learning_statement_topic_subject': row.get('TopicSubject'),\n",
    "        'lesson_learning_statement_topic_sequence': row.get('TopicSequence'),\n",
    "        'lesson_learning_statement_lesson_sequence': row.get('LessonSequence'),\n",
    "        'lesson_learning_statement_sequence': row.get('LearningOutcomeSequence')            \n",
    "    }\n",
    "    logging.pedantic(f\"learning_statement_excel_helper_list: {learning_statement_excel_helper_list}\")\n",
    "\n",
    "    # Replace NaN values with defaults\n",
    "    learning_statement_excel_node_data_processed = replace_nan_with_default(learning_statement_node_data, default_values)\n",
    "    logging.pedantic(f\"processed_data: {learning_statement_excel_node_data_processed}\")\n",
    "\n",
    "    # Create a LearningStatementNode instance for each row\n",
    "    try:\n",
    "        learning_statement_node = LearningStatementNode(**learning_statement_excel_node_data_processed)\n",
    "        logging.pedantic(f\"learning_statement_node: {learning_statement_node}\")\n",
    "        combined_data = {\n",
    "            'node': learning_statement_node,\n",
    "            'helper': learning_statement_excel_helper_data\n",
    "        }\n",
    "        logging.pedantic(f\"combined_data: {combined_data}\")\n",
    "        learning_statement_excel_node_list.append(combined_data)\n",
    "        logging.pedantic(f\"Appended new combined data to learning_statement_excel_node_list, current length: {len(learning_statement_excel_node_list)}\")\n",
    "    except ValidationError as e:\n",
    "        logging.error(f\"Validation error for row {index}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, use the create_or_merge_neontology_node function to add these nodes to your Neo4j database\n",
    "for node_data in learning_statement_excel_node_list:\n",
    "    try:\n",
    "        logging.pedantic(f\"Creating or merging node: {node_data}\")\n",
    "        neon.create_or_merge_neontology_node(node_data['node'], operation='merge')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing node: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_list = []\n",
    "for topic_lesson_node in topic_lesson_excel_node_list:\n",
    "    topic_lesson_node_id = topic_lesson_node['node'].topic_lesson_id\n",
    "    lesson_nodes = neo4j.find_nodes_by_label_and_properties(neo4j_driver, 'TopicLessonNode', {'TopicLessonID': topic_lesson_node_id})\n",
    "    if not lesson_nodes:  # Check if the list is empty\n",
    "        logging.error(f\"No lesson node found for ID {topic_lesson_node_id}\")\n",
    "        continue\n",
    "\n",
    "    topic_node_id = topic_lesson_node['helper']['topic_lesson_topic_id']\n",
    "    topic_nodes = neo4j.find_nodes_by_label_and_properties(neo4j_driver, 'TopicNode', {'topic_id': topic_node_id})\n",
    "    if not topic_nodes:  # Check if the list is empty\n",
    "        logging.error(f\"No topic node found for ID {topic_node_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Assuming only one node is expected for each query\n",
    "    lesson_node = lesson_nodes[0]\n",
    "    topic_node = topic_nodes[0]\n",
    "\n",
    "    # might not be needed\n",
    "    relationship_data = {\n",
    "        'from_node_id': topic_lesson_node_id,\n",
    "        'to_node_id': topic_node_id,\n",
    "        'relationship_type': 'HAS_TOPIC'\n",
    "    }\n",
    "    # needed\n",
    "    topic_node = neo4j.find_nodes_by_label_and_properties(neo4j_driver, 'TopicNode', {'topic_id': topic_node_id})\n",
    "    logging.pedantic(f\"topic_node: {topic_node}\")\n",
    "    topic_has_lesson_relationship = TopicIncludesTopicLesson(source=topic_node, target=lesson_node)\n",
    "    logging.pedantic(f\"topic_has_lesson_relationship: {topic_has_lesson_relationship}\")\n",
    "    relationship_list.append(relationship_data) # maybe don't bother with this list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relationship in relationship_list:\n",
    "    try:\n",
    "        logging.pedantic(f\"Processing relationship: {relationship}\")\n",
    "        SourceNode = TopicNode\n",
    "        TargetNode = TopicLessonNode\n",
    "        relationship_node = TopicIncludesTopicLesson(source=SourceNode(topic_id=relationship['from_node_id']), target=TargetNode(topic_lesson_id=relationship['to_node_id']))\n",
    "        logging.pedantic(f\"relationship_node: {relationship_node}\")\n",
    "        neon.create_or_merge_neontology_relationship(**relationship_node)\n",
    "        logging.pedantic(f\"Relationship processed: {relationship}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing relationship: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed with the next stage of your project, you need to define schemas for the relationships between your Neo4j nodes. Based on the nodes you have provided, it seems you're working with an educational or curricular data model. I'll suggest some potential relationships based on common educational structures, and then show you how to implement them in code.\n",
    "\n",
    "### Suggested Relationship Schemas\n",
    "\n",
    "1. **SchoolContainsSubject**: A relationship from `SchoolNode` to `SubjectNode`, indicating that a subject is taught in a school.\n",
    "2. **SubjectIncludesKeyStage**: A relationship from `SubjectNode` to `KeyStageNode`, suggesting that a subject includes a particular key stage.\n",
    "3. **KeyStageCoversTopic**: A relationship from `KeyStageNode` to `TopicNode`, indicating that a topic is covered in a certain key stage.\n",
    "4. **TopicIncludesLesson**: A relationship from `TopicNode` to `TopicLessonNode`, showing that a lesson is part of a topic.\n",
    "5. **LessonHasLearningStatement**: A relationship from `TopicLessonNode` to `LearningStatementNode`, indicating that a lesson includes a particular learning statement.\n",
    "6. **LessonUtilizesScienceLab**: A relationship from `TopicLessonNode` to `ScienceLabNode`, suggesting that a lesson utilizes a certain science lab.\n",
    "\n",
    "### Implementing Relationship Schemas\n",
    "\n",
    "First, define the relationship classes in your `schemas.py` or a similar file:\n",
    "\n",
    "```python\n",
    "from neontology import BaseNode, BaseRelationship\n",
    "\n",
    "class SchoolContainsSubject(BaseRelationship):\n",
    "    source: SchoolNode\n",
    "    target: SubjectNode\n",
    "\n",
    "class SubjectIncludesKeyStage(BaseRelationship):\n",
    "    source: SubjectNode\n",
    "    target: KeyStageNode\n",
    "\n",
    "class KeyStageCoversTopic(BaseRelationship):\n",
    "    source: KeyStageNode\n",
    "    target: TopicNode\n",
    "\n",
    "class TopicIncludesLesson(BaseRelationship):\n",
    "    source: TopicNode\n",
    "    target: TopicLessonNode\n",
    "\n",
    "class LessonHasLearningStatement(BaseRelationship):\n",
    "    source: TopicLessonNode\n",
    "    target: LearningStatementNode\n",
    "\n",
    "class LessonUtilizesScienceLab(BaseRelationship):\n",
    "    source: TopicLessonNode\n",
    "    target: ScienceLabNode\n",
    "```\n",
    "\n",
    "### Writing Code to Run Them\n",
    "\n",
    "You already have the `create_or_merge_neontology_relationship` function, which you can use to create or merge these relationships. Here's an example of how you might use it in your main notebook:\n",
    "\n",
    "```python\n",
    "# Example of creating a relationship between a school and a subject\n",
    "school_node = SchoolNode(school_id=\"SCH123\", school_name=\"Example School\", ...)\n",
    "subject_node = SubjectNode(subject_id=\"SUB456\", subject=\"Mathematics\", ...)\n",
    "\n",
    "school_subject_rel = SchoolContainsSubject(source=school_node, target=subject_node)\n",
    "create_or_merge_neontology_relationship(school_subject_rel)\n",
    "\n",
    "# Similarly, create other relationships\n",
    "# ...\n",
    "\n",
    "# Don't forget to handle exceptions and log appropriately\n",
    "```\n",
    "\n",
    "You will need to populate the nodes (`school_node`, `subject_node`, etc.) with actual data from your database or data source. The relationships should mirror the structure and connections of your educational model.\n",
    "\n",
    "This setup allows for a flexible and expandable system that can be further customized or extended as your project grows. Remember to always test your code with a small subset of data before scaling up to your entire database to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_tools.create_nodes(neo4j_driver, topic_node_list)\n",
    "neo4j_tools.create_nodes(neo4j_driver, topic_lesson_node_list)\n",
    "neo4j_tools.create_nodes(neo4j_driver, learning_statement_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create relationships between the nodes\n",
    "relationship_list = []\n",
    "topic_nodes = neo4j_tools.find_nodes_by_label(neo4j_driver, 'Topic')\n",
    "topic_lesson_nodes = neo4j_tools.find_nodes_by_label(neo4j_driver, 'TopicLesson')\n",
    "learning_statement_nodes = neo4j_tools.find_nodes_by_label(neo4j_driver, 'LearningStatement')\n",
    "\n",
    "logging.info(f\"topic_nodes: {topic_nodes}\")\n",
    "logging.info(f\"topic_lesson_nodes: {topic_lesson_nodes}\")\n",
    "logging.info(f\"learning_statement_nodes: {learning_statement_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
